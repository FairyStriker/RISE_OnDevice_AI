import os
import time
import json
import cv2
import platform
import gc
import torch
from ultralytics import YOLO
import numpy as np

class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(NumpyEncoder, self).default(obj)

# --- âš™ï¸ 1. Jetson ì‚¬ìš©ì ì„¤ì • ---

# [âœ… ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì„¤ì •] 
# 'name'ì— ì ì€ ì´ë¦„ì´ ê²°ê³¼ JSONì˜ "Key(ì´ë¦„í‘œ)"ê°€ ë©ë‹ˆë‹¤.
MODELS_CONFIG = [
    {
        "name": "yolov8n_fp16", 
        "path": "/home/laheckaf/ssj/models/FP16/yolov8n_fp16.engine"
    },
    {
        "name": "yolov8s_fp16",  
        "path": "/home/laheckaf/ssj/models/FP16/yolov8s_fp16.engine"
    },
    {
        "name": "yolov8m_fp16",  
        "path": "/home/laheckaf/ssj/models/FP16/yolov8m_fp16.engine"
    },
    {
        "name": "yolov8l_fp16",  
        "path": "/home/laheckaf/ssj/models/FP16/yolov8l_fp16.engine"
    },
    {
        "name": "yolov8n_int8",  
        "path": "/home/laheckaf/ssj/models/INT8/yolov8n_int8.engine"
    },
    {
        "name": "yolov8s_int8",  
        "path": "/home/laheckaf/ssj/models/INT8/yolov8s_int8.engine"
    },
    {
        "name": "yolov8m_int8",  
        "path": "/home/laheckaf/ssj/models/INT8/yolov8m_int8.engine"
    },
    {
        "name": "yolov8l_int8",  
        "path": "/home/laheckaf/ssj/models/INT8/yolov8l_int8.engine"
    }
]

# [ê²€ì¦ ì„¤ì •]
DATA_YAML_PATH = '/home/laheckaf/dataset/data.yaml'
IMG_SIZE = 640
IOU_THRESHOLD = 0.50
CONF_THRESHOLD = 0.20

# [FPS ì¸¡ì • ì„¤ì •]
FPS_IMAGE_PATH = 'test_fps.jpg' 
WARMUP_RUNS = 10
FPS_ITERATIONS = 100

# [ê²°ê³¼ ì €ì¥]
RESULTS_FILE_PATH = 'benchmark_results_all_models.json'

# --- (ì„¤ì • ë) ---

def prepare_common_files():
    """ê³µí†µ íŒŒì¼ í™•ì¸ ë° ì¤€ë¹„"""
    if not os.path.exists(DATA_YAML_PATH):
        print(f"âŒ ì˜¤ë¥˜: ë°ì´í„°ì…‹ YAML íŒŒì¼ ì—†ìŒ - {DATA_YAML_PATH}")
        return False
        
    global FPS_IMAGE_PATH
    if not os.path.exists(FPS_IMAGE_PATH):
        try:
            from ultralytics.utils.downloads import GITHUB_ASSETS_DIR
            img_path_obj = GITHUB_ASSETS_DIR / 'bus.jpg'
            if not img_path_obj.exists():
                torch.hub.download_url_to_file('https://ultralytics.com/images/bus.jpg', 'bus.jpg')
            FPS_IMAGE_PATH = 'bus.jpg'
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    return True

def evaluate_single_model(model_config):
    """ê°œë³„ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰"""
    
    model_name = model_config['name']
    model_path = model_config['path']
    device_target = 0 

    print(f"\n" + "="*50)
    print(f"ğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘: [{model_name}]")
    print(f"ğŸ“ ê²½ë¡œ: {model_path}")
    print(f"="*50)

    if not os.path.exists(model_path):
        print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ ì—†ìŒ ({model_path}). ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    # ê²°ê³¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬
    result = {
        'model_path': model_path,
        'img_size': IMG_SIZE,
        'conf_threshold': CONF_THRESHOLD,
        'iou_threshold': IOU_THRESHOLD,
        'platform': f"Jetson ({platform.machine()})",
        'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
    }

    try:
        # 1. ëª¨ë¸ ë¡œë“œ
        print(f"[1/3] ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model = YOLO(model_path)
        
        # 2. ì •í™•ë„ ì¸¡ì •
        print(f"[2/3] ì •í™•ë„(mAP) ì¸¡ì • ì‹œì‘...")
        metrics = model.val(
            data=DATA_YAML_PATH,
            imgsz=IMG_SIZE,
            split='val',
            iou=IOU_THRESHOLD,
            conf=CONF_THRESHOLD,
            device=device_target,
            verbose=False
        )
        
        result['mAP50-95'] = metrics.box.map
        result['mAP50'] = metrics.box.map50
        result['Precision'] = metrics.box.p[0] if isinstance(metrics.box.p, list) else metrics.box.p
        result['Recall'] = metrics.box.r[0] if isinstance(metrics.box.r, list) else metrics.box.r
        
        # F1 Score ê³„ì‚°
        p, r = result['Precision'], result['Recall']
        result['F1_Score'] = 2 * (p * r) / (p + r) if (p + r) > 0 else 0.0

        # 3. FPS ì¸¡ì •
        print(f"[3/3] FPS ì†ë„ ì¸¡ì • ì‹œì‘...")
        img = cv2.imread(FPS_IMAGE_PATH)
        if img is None: raise Exception("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")

        # ì›Œë°ì—…
        for _ in range(WARMUP_RUNS):
            model.predict(img, imgsz=IMG_SIZE, device=device_target, verbose=False)

        # ì‹¤ì œ ì¸¡ì •
        start_time = time.perf_counter()
        for _ in range(FPS_ITERATIONS):
            model.predict(img, imgsz=IMG_SIZE, conf=CONF_THRESHOLD, iou=IOU_THRESHOLD, device=device_target, verbose=False)
        end_time = time.perf_counter()

        total_time = end_time - start_time
        result['FPS'] = 1.0 / (total_time / FPS_ITERATIONS)
        result['Avg_Inference_ms'] = (total_time / FPS_ITERATIONS) * 1000
        
        print(f"âœ… [{model_name}] ì™„ë£Œ: {result['FPS']:.2f} FPS / mAP50: {result['mAP50']:.3f}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del model
        del metrics
        torch.cuda.empty_cache()
        gc.collect()

        return result

    except Exception as e:
        print(f"â€¼ï¸ [{model_name}] ì˜¤ë¥˜ ë°œìƒ: {e}")
        result['error'] = str(e)
        return result

def run_all_benchmarks():
    """ëª¨ë“  ëª¨ë¸ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì´ë¦„(Key)ìœ¼ë¡œ ì €ì¥"""
    
    print("--- ğŸš€ Jetson ë‹¤ì¤‘ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ---")
    
    if not prepare_common_files():
        return

    # âœ… ë¦¬ìŠ¤íŠ¸([]) ëŒ€ì‹  ë”•ì…”ë„ˆë¦¬({}) ì‚¬ìš©
    final_results_dict = {}

    for config in MODELS_CONFIG:
        model_name = config['name'] # ì—¬ê¸°ì„œ ì„¤ì •í•œ ì´ë¦„ì„ í‚¤ê°’ìœ¼ë¡œ ì”ë‹ˆë‹¤.
        
        res = evaluate_single_model(config)
        
        if res is not None:
            # âœ… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì´ë¦„ìœ¼ë¡œ ì €ì¥
            final_results_dict[model_name] = res
            
        time.sleep(2) # ì—´ ì‹íˆê¸°

    # ê²°ê³¼ ì €ì¥
    print(f"\n--- ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥ ì¤‘ ---")
    try:
        with open(RESULTS_FILE_PATH, 'w', encoding='utf-8') as f:
            json.dump(final_results_dict, f, ensure_ascii=False, indent=4, cls=NumpyEncoder)
        print(f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {RESULTS_FILE_PATH}")
        
        # ìš”ì•½ ì¶œë ¥
        print("\n--- ğŸ“Š ìµœì¢… ìš”ì•½ ---")
        print(f"{'Model Name':<20} | {'FPS':<10} | {'mAP50':<10} | {'F1-Score':<10}")
        print("-" * 60)
        
        # ë”•ì…”ë„ˆë¦¬ ìˆœíšŒí•˜ë©° ì¶œë ¥
        for name, data in final_results_dict.items():
            if 'error' not in data:
                print(f"{name:<20} | {data['FPS']:<10.2f} | {data['mAP50']:<10.4f} | {data['F1_Score']:<10.4f}")
            else:
                print(f"{name:<20} | ERROR ë°œìƒ")
        print("-" * 60)

    except Exception as e:
        print(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    run_all_benchmarks()
