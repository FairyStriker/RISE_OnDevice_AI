#include <iostream>
#include <fstream>
#include <vector>
#include <string>
#include <chrono>
#include <iomanip> // for setprecision
#include <opencv2/opencv.hpp>
#include <NvInfer.h>
#include <cuda_runtime_api.h>

// --- âš™ï¸ ì‚¬ìš©ì ì„¤ì • (Python ì½”ë“œ ì„¤ì • ë°˜ì˜) ---
const std::string MODEL_PATH = "/home/laheckaf/ssj/models/yolo_n.engine";
const std::string FPS_IMAGE_PATH = "test_fps.jpg"; // ì—†ìœ¼ë©´ bus.jpg ì‚¬ìš© ê¶Œì¥
const std::string RESULTS_FILE_PATH = "benchmark_results_jetson_cpp.json"; // ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…

const int INPUT_W = 640;
const int INPUT_H = 640;
const int WARMUP_RUNS = 10;
const int FPS_ITERATIONS = 100;
// ----------------------------------------------

// TensorRT Logger (í•„ìˆ˜)
class Logger : public nvinfer1::ILogger {
    void log(Severity severity, const char* msg) noexcept override {
        if (severity <= Severity::kWARNING) std::cout << "[TRT] " << msg << std::endl;
    }
} gLogger;

// JSON ì €ì¥ì„ ìœ„í•œ ê°„ë‹¨í•œ í—¬í¼ í•¨ìˆ˜
void save_results_json(double fps, double avg_ms, const std::string& platform_name) {
    std::ofstream jsonFile(RESULTS_FILE_PATH);
    if (jsonFile.is_open()) {
        jsonFile << "{\n";
        jsonFile << "    \"platform\": \"" << platform_name << "\",\n";
        jsonFile << "    \"model\": \"" << MODEL_PATH << "\",\n";
        jsonFile << "    \"img_size\": " << INPUT_W << ",\n";
        jsonFile << "    \"FPS\": " << std::fixed << std::setprecision(2) << fps << ",\n";
        jsonFile << "    \"Avg_Inference_ms\": " << avg_ms << "\n";
        jsonFile << "}";
        jsonFile.close();
        std::cout << "\n--- ğŸ’¾ ê²°ê³¼ ì €ì¥ ---" << std::endl;
        std::cout << "íŒŒì¼ ê²½ë¡œ: " << RESULTS_FILE_PATH << std::endl;
        std::cout << "ê²°ê³¼ê°€ JSON íŒŒì¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤." << std::endl;
    } else {
        std::cerr << "â€¼ï¸ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." << std::endl;
    }
}

int main() {
    std::cout << "--- ğŸš€ Jetson C++ FPS ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ---" << std::endl;

    // 1. ëª¨ë¸ ë¡œë“œ
    std::cout << "\n[1/3] ëª¨ë¸ ë¡œë“œ ì¤‘: " << MODEL_PATH << std::endl;
    std::ifstream file(MODEL_PATH, std::ios::binary);
    if (!file.good()) {
        std::cerr << "ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!" << std::endl;
        return -1;
    }
    file.seekg(0, file.end);
    size_t size = file.tellg();
    file.seekg(0, file.beg);
    std::vector<char> engineData(size);
    file.read(engineData.data(), size);
    file.close();

    nvinfer1::IRuntime* runtime = nvinfer1::createInferRuntime(gLogger);
    nvinfer1::ICudaEngine* engine = runtime->deserializeCudaEngine(engineData.data(), size);
    nvinfer1::IExecutionContext* context = engine->createExecutionContext();

    if (!context) {
        std::cerr << "ì˜¤ë¥˜: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨!" << std::endl;
        return -1;
    }
    std::cout << "ëª¨ë¸ ë¡œë“œ ì™„ë£Œ." << std::endl;

    // 2. ë©”ëª¨ë¦¬ í• ë‹¹
    void* buffers[2];
    size_t inputSize = 1 * 3 * INPUT_H * INPUT_W * sizeof(float);
    size_t outputSize = 1 * 84 * 8400 * sizeof(float); // YOLOv8 Output Size

    cudaMalloc(&buffers[0], inputSize);
    cudaMalloc(&buffers[1], outputSize);
    cudaStream_t stream;
    cudaStreamCreate(&stream);

    // 3. ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    std::cout << "\n[2/3] FPS ì¸¡ì • ì¤€ë¹„ (ì´ë¯¸ì§€: " << FPS_IMAGE_PATH << ")..." << std::endl;
    cv::Mat img = cv::imread(FPS_IMAGE_PATH);
    if (img.empty()) {
        std::cout << "ê²½ê³ : ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ì •ìƒ‰ ë¹ˆ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤." << std::endl;
        img = cv::Mat::zeros(INPUT_H, INPUT_W, CV_8UC3);
    }

    cv::Mat resized;
    cv::resize(img, resized, cv::Size(INPUT_W, INPUT_H));
    cv::cvtColor(resized, resized, cv::COLOR_BGR2RGB);
    resized.convertTo(resized, CV_32FC3, 1.0 / 255.0); // 0~1 ì •ê·œí™”

    // HWC -> CHW ë³€í™˜ (TensorRT í¬ë§·)
    std::vector<float> inputData(1 * 3 * INPUT_H * INPUT_W);
    std::vector<cv::Mat> chw_channels;
    for (int i = 0; i < 3; ++i) {
        chw_channels.push_back(cv::Mat(INPUT_H, INPUT_W, CV_32FC1, inputData.data() + i * INPUT_H * INPUT_W));
    }
    cv::split(resized, chw_channels);

    // ë°ì´í„° GPU ë³µì‚¬
    cudaMemcpyAsync(buffers[0], inputData.data(), inputSize, cudaMemcpyHostToDevice, stream);

    // 4. FPS ì¸¡ì •
    std::cout << "\n[3/3] FPS ì¸¡ì • ì‹œì‘..." << std::endl;
    
    // ì›Œë°ì—…
    std::cout << "ì›Œë°ì—… ì‹¤í–‰ (" << WARMUP_RUNS << "íšŒ)..." << std::endl;
    for (int i = 0; i < WARMUP_RUNS; i++) {
        context->enqueueV2(buffers, stream, nullptr);
    }
    cudaStreamSynchronize(stream);

    // ì‹¤ì œ ì¸¡ì •
    std::cout << "ì„±ëŠ¥ ì¸¡ì • ì‹¤í–‰ (" << FPS_ITERATIONS << "íšŒ)..." << std::endl;
    auto start = std::chrono::high_resolution_clock::now();

    for (int i = 0; i < FPS_ITERATIONS; i++) {
        context->enqueueV2(buffers, stream, nullptr);
    }
    cudaStreamSynchronize(stream);
    auto end = std::chrono::high_resolution_clock::now();

    // ê²°ê³¼ ê³„ì‚°
    double total_time_ms = std::chrono::duration<double, std::milli>(end - start).count();
    double avg_time_ms = total_time_ms / FPS_ITERATIONS;
    double fps = 1000.0 / avg_time_ms;

    // ì½˜ì†” ì¶œë ¥
    std::cout << "FPS ì¸¡ì • ì™„ë£Œ: í‰ê·  " << std::fixed << std::setprecision(2) << fps 
              << " FPS (" << avg_time_ms << " ms)" << std::endl;

    // 5. ê²°ê³¼ íŒŒì¼ ì €ì¥ (JSON)
    save_results_json(fps, avg_time_ms, "Jetson (C++ / TensorRT)");

    std::cout << "\n--- Jetson ìµœì¢… ìš”ì•½ ---" << std::endl;
    std::cout << "{" << std::endl;
    std::cout << "  \"platform\": \"Jetson (C++ / TensorRT)\"," << std::endl;
    std::cout << "  \"FPS\": " << fps << "," << std::endl;
    std::cout << "  \"Avg_ms\": " << avg_time_ms << std::endl;
    std::cout << "}" << std::endl;
    std::cout << "-----------------------" << std::endl;

    // ë¦¬ì†ŒìŠ¤ í•´ì œ
    cudaStreamDestroy(stream);
    cudaFree(buffers[0]);
    cudaFree(buffers[1]);
    delete context;
    delete engine;
    delete runtime;

    return 0;
}